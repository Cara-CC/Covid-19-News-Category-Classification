{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "stunning-prediction",
   "metadata": {},
   "source": [
    "# News Category Classification During Covid-19 Pandemic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-providence",
   "metadata": {},
   "source": [
    "### Team members: Yifan Zhang, Tianqi Cao, Li Du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "norman-isolation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "interpreted-stereo",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('data_before_preprocessing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mineral-thesis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13082"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "useful-works",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13082 entries, 0 to 13081\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Unnamed: 0   13082 non-null  int64 \n",
      " 1   author       13082 non-null  object\n",
      " 2   date         13082 non-null  object\n",
      " 3   domain       13082 non-null  object\n",
      " 4   title        13082 non-null  object\n",
      " 5   url          13082 non-null  object\n",
      " 6   content      13082 non-null  object\n",
      " 7   topic_area   13082 non-null  object\n",
      " 8   domain_code  13082 non-null  int64 \n",
      " 9   topic_code   13082 non-null  int64 \n",
      " 10  type         13082 non-null  object\n",
      "dtypes: int64(3), object(8)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "western-perth",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt') # downloads you a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "enabling-machinery",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "seasonal-luther",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "ps = PorterStemmer()\n",
    "def preprocessing(doc, stemming = True):\n",
    "    \n",
    "    sentences = sent_tokenize(doc)\n",
    "    tokens=[]\n",
    "    for sent in sentences[:5]:\n",
    "        text = re.sub('\\xa0', '', sent)   \n",
    "        \n",
    "        pattern=r'[^a-zA-z\\s]'\n",
    "        text=re.sub(pattern,'',text)\n",
    "        words = word_tokenize(text)\n",
    "        \n",
    "        if stemming:\n",
    "            words = [ps.stem(w) for w in words]        \n",
    "        \n",
    "        tokens=tokens+words\n",
    "    return [w.lower() for w in tokens if w not in stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efficient-interval",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['first_5_sent']=data.content.apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "broken-shower",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [homag, singaporebas, startup, match, famili, ...\n",
       "1    [thi, week, i, wa, vaccin, covid, pfizer, mrna...\n",
       "2    [fund, set, phoeb, wallerbridg, olivia, colman...\n",
       "3    [lo, angel, counti, depart, public, health, co...\n",
       "4    [franc, saw, biggest, ever, monthli, drop, job...\n",
       "Name: first_5_sent, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.first_5_sent.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-receipt",
   "metadata": {},
   "source": [
    "# BOW Binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-drinking",
   "metadata": {},
   "source": [
    "### use 'content' as the sole predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "imposed-forge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "binary = CountVectorizer(lowercase = True,\n",
    "                       preprocessor = None,\n",
    "                       tokenizer = preprocessing, \n",
    "                       binary = True) # Setting this parameter would make the vector only binary form rather than frequency\n",
    "\n",
    "\n",
    "y = data.topic_area.values\n",
    "X1 = binary.fit_transform(data.content) # Transforming doc into binary vector\n",
    "print(type(X1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "funny-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting dataframe into train, validation and test set with 80%/10%/10% ratio and set seed as 42\n",
    "\n",
    "X_train1, X_test_vali1, y_train, y_test_vali = train_test_split(X1, y, test_size = 0.2, random_state = 42)\n",
    "X_vali1, X_test1, y_vali, y_test = train_test_split(X_test_vali1, y_test_vali, test_size = 0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "surprised-hardwood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only content\n",
    "clf = LogisticRegression(random_state=0,\n",
    "                          n_jobs=-1,\n",
    "                         max_iter=300,\n",
    "                         C=0.03).fit(X_train1, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "radical-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "convertible-asbestos",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                 ai&tech       0.59      0.69      0.64       194\n",
      "                business       0.57      0.42      0.49       194\n",
      "construction&environment       0.88      0.64      0.74       131\n",
      "     consumer&automotive       0.83      0.85      0.84       190\n",
      "                 finance       0.62      0.70      0.65       187\n",
      "                 general       0.69      0.71      0.70       221\n",
      "      science&healthcare       0.73      0.82      0.77       192\n",
      "\n",
      "                accuracy                           0.69      1309\n",
      "               macro avg       0.70      0.69      0.69      1309\n",
      "            weighted avg       0.69      0.69      0.69      1309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-junction",
   "metadata": {},
   "source": [
    "### use both 'content' and 'domain' as predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "continental-episode",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = binary.fit_transform(data.domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "regular-centre",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test_vali2, y_train, y_test_vali = train_test_split(X2, y, test_size = 0.2, random_state = 42)\n",
    "X_vali2, X_test2, y_vali, y_test = train_test_split(X_test_vali2, y_test_vali, test_size = 0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "classified-appeal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix, bmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "pointed-retrieval",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = bmat([[X_train1,X_train2]])\n",
    "X_test = bmat([[X_test1, X_test2]])\n",
    "X_vali = bmat([[X_vali1, X_vali2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "union-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both content and domain\n",
    "clf = LogisticRegression(random_state=0,\n",
    "                          n_jobs=-1,\n",
    "                         max_iter=300,\n",
    "                         C=0.7).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eligible-juice",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "blocked-porter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                 ai&tech       0.95      0.99      0.97       194\n",
      "                business       1.00      0.98      0.99       194\n",
      "construction&environment       0.99      0.99      0.99       131\n",
      "     consumer&automotive       0.99      0.99      0.99       190\n",
      "                 finance       1.00      0.98      0.99       187\n",
      "                 general       1.00      0.98      0.99       221\n",
      "      science&healthcare       0.98      0.99      0.99       192\n",
      "\n",
      "                accuracy                           0.99      1309\n",
      "               macro avg       0.99      0.99      0.99      1309\n",
      "            weighted avg       0.99      0.99      0.99      1309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-engine",
   "metadata": {},
   "source": [
    "# BOW Term Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-proof",
   "metadata": {},
   "source": [
    "### use 'content' as the sole predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "instant-cartoon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "tf = CountVectorizer(lowercase = True,\n",
    "                       preprocessor = None,\n",
    "                       tokenizer = preprocessing, \n",
    "                       binary = False) # Setting this parameter would make the vector only binary form rather than frequency\n",
    "\n",
    "\n",
    "y = data.topic_area.values\n",
    "X1 = tf.fit_transform(data.content) # Transforming doc into tf vector\n",
    "print(type(X1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "steady-traffic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting dataframe into train, validation and test set with 80%/10%/10% ratio and set seed as 42\n",
    "X_train1, X_test_vali1, y_train, y_test_vali = train_test_split(X1, y, test_size = 0.2, random_state = 42)\n",
    "X_vali1, X_test1, y_vali, y_test = train_test_split(X_test_vali1, y_test_vali, test_size = 0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "simple-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only content\n",
    "clf = LogisticRegression(random_state=0,\n",
    "                          n_jobs=-1,\n",
    "                         max_iter=300,\n",
    "                         C=0.03).fit(X_train1, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "turned-identifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acoustic-luther",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                 ai&tech       0.67      0.70      0.68       194\n",
      "                business       0.57      0.47      0.51       194\n",
      "construction&environment       0.86      0.69      0.76       131\n",
      "     consumer&automotive       0.87      0.85      0.86       190\n",
      "                 finance       0.60      0.65      0.63       187\n",
      "                 general       0.67      0.69      0.68       221\n",
      "      science&healthcare       0.72      0.85      0.78       192\n",
      "\n",
      "                accuracy                           0.70      1309\n",
      "               macro avg       0.71      0.70      0.70      1309\n",
      "            weighted avg       0.70      0.70      0.70      1309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-orlando",
   "metadata": {},
   "source": [
    "### use both content and domain as predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "sized-royalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = tf.fit_transform(data.domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "integral-bryan",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test_vali2, y_train, y_test_vali = train_test_split(X2, y, test_size = 0.2, random_state = 42)\n",
    "X_vali2, X_test2, y_vali, y_test = train_test_split(X_test_vali2, y_test_vali, test_size = 0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "inner-support",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = bmat([[X_train1,X_train2]])\n",
    "X_test = bmat([[X_test1, X_test2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "radio-rugby",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0,\n",
    "                          n_jobs=-1,\n",
    "                         max_iter=300,\n",
    "                         C=0.7).fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "neutral-bridge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                 ai&tech       0.94      0.98      0.96       194\n",
      "                business       0.98      0.97      0.97       194\n",
      "construction&environment       0.98      0.98      0.98       131\n",
      "     consumer&automotive       0.98      0.99      0.98       190\n",
      "                 finance       1.00      0.96      0.98       187\n",
      "                 general       1.00      0.97      0.98       221\n",
      "      science&healthcare       0.97      0.98      0.98       192\n",
      "\n",
      "                accuracy                           0.98      1309\n",
      "               macro avg       0.98      0.98      0.98      1309\n",
      "            weighted avg       0.98      0.98      0.98      1309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-traffic",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "standing-checklist",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13082/13082 [00:00<00:00, 21322.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# count the appearance of each token in all reviews and build a dict: the key is the token, and the item is the frequency\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "DF = defaultdict(float)\n",
    "for c in tqdm(data.first_5_sent):\n",
    "    for token in set(c):\n",
    "        DF[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "endangered-return",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43581 2323\n"
     ]
    }
   ],
   "source": [
    "from math import log\n",
    "IDF, vocab = dict(), dict()\n",
    "for token in DF:\n",
    "    if DF[token] < 55:\n",
    "        # this becomes an unk\n",
    "        pass\n",
    "    else:\n",
    "        vocab[token] = len(vocab)\n",
    "        IDF[token] = log(1 + len(data) / DF[token])\n",
    "        \n",
    "print(len(DF), len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ongoing-native",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDF['<UNK>'] = 1\n",
    "vocab['<UNK>'] = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "severe-worship",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that computes weight of each token in a review\n",
    "\n",
    "def tfidf_feature_extractor(tokens, vocab, IDF):\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token not in vocab:\n",
    "            tokens[i] = '<UNK>'\n",
    "    TF = defaultdict(int)\n",
    "    for token in tokens:\n",
    "        TF[token] += 1\n",
    "    x = [0] * len(vocab)\n",
    "    for token in set(tokens):\n",
    "        tfidf = log(TF[token] + 1) * IDF[token]\n",
    "        token_id = vocab[token]\n",
    "        x[token_id] = tfidf \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "later-apollo",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13082/13082 [00:01<00:00, 12655.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# call tfidf_feature_extractor function on each review and get matrixes of all tokens' weight in all reviews\n",
    "\n",
    "score=[]\n",
    "for t in tqdm(data.first_5_sent):\n",
    "    score.append(tfidf_feature_extractor(t, vocab, IDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "armed-moscow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'author', 'date', 'domain', 'title', 'url', 'content',\n",
       "       'topic_area', 'domain_code', 'topic_code', 'type', 'first_5_sent'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "preceding-ending",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tfidf']=score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "greek-deputy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb=LabelBinarizer()\n",
    "lb.fit(data.domain)\n",
    "domain_bi = lb.transform(data.domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "challenging-apparatus",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.assign(domain_bi=list(domain_bi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "qualified-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_df=pd.concat([data.domain_bi, data.tfidf],axis=1)\n",
    "data['domain_tfidf']=two_df.apply(lambda row: list(row[\"domain_bi\"])+row[\"tfidf\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "rubber-experience",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "ymd=data.date.apply(lambda x:datetime.strptime(x, '%Y-%m-%d'))\n",
    "data=data.assign(month=ymd.map(lambda x: x.month))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "adopted-rebel",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb=LabelBinarizer()\n",
    "lb.fit(data.month)\n",
    "month_bi = lb.transform(data.month)\n",
    "data=data.assign(month_bi=list(month_bi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fancy-disability",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([data.tfidf, data.month_bi],axis=1)\n",
    "data['tfidf_month']=df.apply(lambda row: list(row[\"tfidf\"])+list(row[\"month_bi\"]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "comic-struggle",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_vt, y_train, y_vt = train_test_split(data, data.topic_area, test_size = 0.2, random_state = 42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_vt, y_vt, test_size = 0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generic-continuity",
   "metadata": {},
   "source": [
    "### Logistic regression models, use tfidf, tfidf+month, and tfidf+domain as predictor(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "acquired-modern",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use only one variable(tf-idf score) to predict news type\n",
    "\n",
    "clf_lr1 = LogisticRegression(max_iter=10000, C=0.7).fit(list(X_train['tfidf']), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "verbal-boundary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                 ai&tech       0.59      0.60      0.59       194\n",
      "                business       0.44      0.43      0.43       194\n",
      "construction&environment       0.74      0.63      0.68       131\n",
      "     consumer&automotive       0.84      0.79      0.82       190\n",
      "                 finance       0.50      0.60      0.55       187\n",
      "                 general       0.64      0.61      0.63       221\n",
      "      science&healthcare       0.72      0.75      0.73       192\n",
      "\n",
      "                accuracy                           0.63      1309\n",
      "               macro avg       0.64      0.63      0.63      1309\n",
      "            weighted avg       0.63      0.63      0.63      1309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_pred1 = clf_lr1.predict(list(X_test['tfidf']))\n",
    "print(classification_report(y_test, lr_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "located-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use two variables (tf-idf score and month_binary code) to predict news type\n",
    "\n",
    "clf_lr2 = LogisticRegression(max_iter=10000, C=0.7).fit(list(X_train['tfidf_month']), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "acute-lloyd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                 ai&tech       0.60      0.61      0.61       194\n",
      "                business       0.48      0.48      0.48       194\n",
      "construction&environment       0.76      0.61      0.68       131\n",
      "     consumer&automotive       0.84      0.79      0.82       190\n",
      "                 finance       0.50      0.59      0.54       187\n",
      "                 general       0.65      0.62      0.64       221\n",
      "      science&healthcare       0.71      0.77      0.74       192\n",
      "\n",
      "                accuracy                           0.64      1309\n",
      "               macro avg       0.65      0.64      0.64      1309\n",
      "            weighted avg       0.65      0.64      0.64      1309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_pred2 = clf_lr2.predict(list(X_test['tfidf_month']))\n",
    "\n",
    "print(classification_report(y_test, lr_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "satellite-seating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use two variables (tf-idf score and domain_binary code) to predict news type\n",
    "\n",
    "clf_lr3 = LogisticRegression(max_iter=10000, C=0.7).fit(list(X_train['domain_tfidf']), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "harmful-examination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                 ai&tech       0.86      0.91      0.88       194\n",
      "                business       0.88      0.89      0.88       194\n",
      "construction&environment       0.93      0.87      0.90       131\n",
      "     consumer&automotive       0.92      0.96      0.94       190\n",
      "                 finance       0.97      0.93      0.95       187\n",
      "                 general       0.95      0.92      0.93       221\n",
      "      science&healthcare       0.88      0.89      0.89       192\n",
      "\n",
      "                accuracy                           0.91      1309\n",
      "               macro avg       0.91      0.91      0.91      1309\n",
      "            weighted avg       0.91      0.91      0.91      1309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_pred3 = clf_lr3.predict(list(X_test['domain_tfidf']))\n",
    "\n",
    "print(classification_report(y_test, lr_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-childhood",
   "metadata": {},
   "source": [
    "### XGBoost models using tfidf, tfidf+month, and tfidf+domain as predictor(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "norman-watts",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "affecting-upset",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb1 = xgb.XGBClassifier(max_depth=4,\n",
    "                            n_estimators=100,\n",
    "                            objective=\"multi:softmax\",\n",
    "                            num_class=7, \n",
    "                            eval_metric=\"auc\",                            \n",
    "                            random_state=42).fit(np.vstack(X_train['tfidf']), y_train,  verbose=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "recreational-bloom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                 ai&tech       0.60      0.68      0.64       194\n",
      "                business       0.65      0.52      0.57       194\n",
      "construction&environment       0.86      0.73      0.79       131\n",
      "     consumer&automotive       0.87      0.87      0.87       190\n",
      "                 finance       0.68      0.70      0.69       187\n",
      "                 general       0.68      0.72      0.70       221\n",
      "      science&healthcare       0.78      0.85      0.82       192\n",
      "\n",
      "                accuracy                           0.72      1309\n",
      "               macro avg       0.73      0.72      0.73      1309\n",
      "            weighted avg       0.73      0.72      0.72      1309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_pred1 = clf_xgb1.predict(np.vstack(X_test['tfidf']))\n",
    "\n",
    "print(classification_report(y_test, xgb_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "corresponding-drive",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb2 = xgb.XGBClassifier(max_depth=4,\n",
    "                            n_estimators=100,\n",
    "                            objective=\"multi:softmax\",\n",
    "                            num_class=7, \n",
    "                            eval_metric=\"auc\",                            \n",
    "                            random_state=42).fit(np.vstack(X_train['tfidf_month']), y_train,  verbose=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "grave-orbit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                 ai&tech       0.60      0.63      0.61       194\n",
      "                business       0.62      0.56      0.59       194\n",
      "construction&environment       0.81      0.69      0.75       131\n",
      "     consumer&automotive       0.87      0.88      0.87       190\n",
      "                 finance       0.68      0.69      0.68       187\n",
      "                 general       0.72      0.75      0.74       221\n",
      "      science&healthcare       0.80      0.83      0.82       192\n",
      "\n",
      "                accuracy                           0.72      1309\n",
      "               macro avg       0.73      0.72      0.72      1309\n",
      "            weighted avg       0.72      0.72      0.72      1309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_pred2 = clf_xgb2.predict(np.vstack(X_test['tfidf_month']))\n",
    "\n",
    "print(classification_report(y_test, xgb_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "hundred-colony",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb3 = xgb.XGBClassifier(max_depth=4,\n",
    "                            n_estimators=100,\n",
    "                            objective=\"multi:softmax\",\n",
    "                            num_class=7, \n",
    "                            eval_metric=\"auc\",                            \n",
    "                            random_state=42).fit(np.vstack(X_train['domain_tfidf']), y_train,  verbose=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "weird-usage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                 ai&tech       0.99      1.00      0.99       194\n",
      "                business       0.99      0.99      0.99       194\n",
      "construction&environment       1.00      1.00      1.00       131\n",
      "     consumer&automotive       1.00      1.00      1.00       190\n",
      "                 finance       1.00      0.99      1.00       187\n",
      "                 general       1.00      1.00      1.00       221\n",
      "      science&healthcare       1.00      1.00      1.00       192\n",
      "\n",
      "                accuracy                           1.00      1309\n",
      "               macro avg       1.00      1.00      1.00      1309\n",
      "            weighted avg       1.00      1.00      1.00      1309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_pred3 = clf_xgb3.predict(np.vstack(X_test['domain_tfidf']))\n",
    "\n",
    "print(classification_report(y_test, xgb_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "following-jason",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "logical-origin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import Counter\n",
    "import os\n",
    "from gensim.models import word2vec\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "novel-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function used to learn word embeddings through Word2vec module\n",
    "def get_embeddings(inp_data, vocabulary_inv, size_features=100,\n",
    "                   mode='skipgram',\n",
    "                   min_word_count=2,\n",
    "                   context=5):\n",
    "    model_name = \"embedding\"\n",
    "    model_name = os.path.join(model_name)\n",
    "    num_workers = 15  # Number of threads to run in parallel\n",
    "    downsampling = 1e-3  # Downsample setting for frequent words\n",
    "    print('Training Word2Vec model...')\n",
    "    # use inp_data and vocabulary_inv to reconstruct sentences\n",
    "    sentences = [[vocabulary_inv[w] for w in s] for s in inp_data]\n",
    "    if mode == 'skipgram':\n",
    "        sg = 1\n",
    "        print('Model: skip-gram')\n",
    "    elif mode == 'cbow':\n",
    "        sg = 0\n",
    "        print('Model: CBOW')\n",
    "    embedding_model = word2vec.Word2Vec(sentences, workers=num_workers,\n",
    "                                        sg=sg,\n",
    "                                        size=size_features,\n",
    "                                        min_count=min_word_count,\n",
    "                                        window=context,\n",
    "                                        sample=downsampling)\n",
    "    embedding_model.init_sims(replace=True)\n",
    "    print(\"Saving Word2Vec model {}\".format(model_name))\n",
    "    embedding_weights = np.zeros((len(vocabulary_inv), size_features))\n",
    "    for i in range(len(vocabulary_inv)):\n",
    "        word = vocabulary_inv[i]\n",
    "        if word in embedding_model:\n",
    "            embedding_weights[i] = embedding_model[word]\n",
    "        else:\n",
    "            embedding_weights[i] = np.random.uniform(-0.25, 0.25,\n",
    "                                                     embedding_model.vector_size)\n",
    "    return embedding_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "interstate-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df):\n",
    "    # get English stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.add('would')\n",
    "    # prepare translation table to translate punctuation to space\n",
    "    translator = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n",
    "    preprocessed_sentences = []\n",
    "    for i, row in df.iterrows():\n",
    "        sent = row['text']\n",
    "        sent_nopuncts = sent.translate(translator)\n",
    "        words_list = sent_nopuncts.strip().split()\n",
    "        filtered_words = [word for word in words_list if word not in stop_words and len(word) != 1] # also skip space from above translation\n",
    "        preprocessed_sentences.append(\" \".join(filtered_words))\n",
    "    df[\"text\"] = preprocessed_sentences\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "little-translation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function used to build a vocabulary based on descending word frequencies \n",
    "def build_vocab(sentences):\n",
    "    # Build vocabulary\n",
    "    word_counts = Counter(itertools.chain(*sentences))\n",
    "    # Mapping from index to word\n",
    "    vocabulary_inv = [x[0] for x in word_counts.most_common()]\n",
    "    # Mapping from word to index\n",
    "    vocabulary = {x: i for i, x in enumerate(vocabulary_inv)}\n",
    "    return word_counts, vocabulary, vocabulary_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "million-memory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec model...\n",
      "Model: skip-gram\n",
      "Saving Word2Vec model embedding\n"
     ]
    }
   ],
   "source": [
    "data[\"text\"] = data[\"content\"]\n",
    "df = preprocess_df(data)\n",
    "\n",
    "# tokenization \n",
    "tagged_data = [word_tokenize(_d) for i, _d in enumerate(df[\"text\"])]\n",
    "# build vocabulary from tokenized data\n",
    "word_counts, vocabulary, vocabulary_inv = build_vocab(tagged_data)\n",
    "# use the above mapping to create input data\n",
    "inp_data = [[vocabulary[word] for word in text] for text in tagged_data]\n",
    "# get embedding vector\n",
    "embedding_weights = get_embeddings(inp_data, vocabulary_inv)\n",
    "\n",
    "\n",
    "tagged_data = [word_tokenize(_d) for i, _d in enumerate(df[\"text\"])]\n",
    "\n",
    "data_vec = []\n",
    "for doc in tagged_data:\n",
    "    vec = 0\n",
    "    for w in doc:\n",
    "        vec += embedding_weights[vocabulary[w]]\n",
    "    vec = vec / len(doc)\n",
    "    data_vec.append(vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "integrated-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['w2v'] = data_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "protected-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_vt, y_train, y_vt = train_test_split(data, data.topic_area, test_size = 0.2, random_state = 42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_vt, y_vt, test_size = 0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-belle",
   "metadata": {},
   "source": [
    "### Logistic Regression using 'content' as the only predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "sunset-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_lr1 = LogisticRegression(max_iter=1000000, C = 1000, random_state=42).fit(list(X_train['w2v']), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "finished-apparatus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                 ai&tech       0.62      0.70      0.66       194\n",
      "                business       0.60      0.52      0.56       194\n",
      "construction&environment       0.82      0.76      0.79       131\n",
      "     consumer&automotive       0.75      0.74      0.74       190\n",
      "                 finance       0.65      0.75      0.70       187\n",
      "                 general       0.78      0.68      0.73       221\n",
      "      science&healthcare       0.76      0.82      0.79       192\n",
      "\n",
      "                accuracy                           0.71      1309\n",
      "               macro avg       0.71      0.71      0.71      1309\n",
      "            weighted avg       0.71      0.71      0.71      1309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w2v_lr1_pred = w2v_lr1.predict(list(X_test['w2v']))\n",
    "\n",
    "print(classification_report(y_test, w2v_lr1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "alleged-thread",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = [1000, 100, 10, 1, 0.5, 0.25, 0.1, 0.05, 0.025, 0.01, 0.005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "illegal-nigeria",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=3)]: Done  35 out of  35 | elapsed:   18.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "lr_cv = LogisticRegressionCV(Cs=Cs,\n",
    "                           cv=5,\n",
    "                           solver='liblinear',\n",
    "                           scoring='accuracy',\n",
    "                           random_state=42,\n",
    "                           n_jobs=3,\n",
    "                           verbose=3,\n",
    "                           max_iter=100000000,\n",
    "                           penalty='l2').fit(list(X_train['w2v']), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "south-runner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of LogisticRegressionCV(Cs=[1000, 100, 10, 1, 0.5, 0.25, 0.1, 0.05, 0.025, 0.01,\n",
       "                         0.005],\n",
       "                     cv=5, max_iter=100000000, n_jobs=3, random_state=42,\n",
       "                     scoring='accuracy', solver='liblinear', verbose=3)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_cv.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "peripheral-investigation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6995412844036697"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_cv.score(list(X_val['w2v']), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "wrapped-roulette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                 ai&tech       0.63      0.71      0.66       194\n",
      "                business       0.66      0.49      0.56       194\n",
      "construction&environment       0.83      0.79      0.81       131\n",
      "     consumer&automotive       0.77      0.76      0.76       190\n",
      "                 finance       0.64      0.76      0.69       187\n",
      "                 general       0.79      0.70      0.74       221\n",
      "      science&healthcare       0.75      0.82      0.79       192\n",
      "\n",
      "                accuracy                           0.72      1309\n",
      "               macro avg       0.72      0.72      0.72      1309\n",
      "            weighted avg       0.72      0.72      0.71      1309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_pred = lr_cv.predict(list(X_test['w2v']))\n",
    "\n",
    "print(classification_report(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-dominant",
   "metadata": {},
   "source": [
    "### Neural Network using 'content' as the only predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "excellent-thumb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural net from SKLEARN\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "nn = MLPClassifier(\n",
    "    activation=\"tanh\",\n",
    "    solver=\"lbfgs\",\n",
    "    alpha=0.01,\n",
    "    hidden_layer_sizes=(3,),\n",
    "    random_state=42,\n",
    "    max_iter=10000,\n",
    ").fit(list(X_train['w2v']), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "enhanced-cathedral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5986238532110092"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.score(list(X_val['w2v']), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dramatic-convention",
   "metadata": {
    "lines_to_next_cell": 0,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# alpha is the level of regularization\n",
    "hls = [(6,), (7,), (8, )]\n",
    "param_grid = {\"hidden_layer_sizes\": hls, \"alpha\": [0.01, 0.001]}\n",
    "#scoring = {\"AUC\": \"roc_auc\"}\n",
    "\n",
    "nn_cv = GridSearchCV(\n",
    "    nn, param_grid, scoring='accuracy', cv=5, n_jobs=4, verbose=5\n",
    ").fit(list(X_train['w2v']), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "medium-conflict",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.01, 'hidden_layer_sizes': (8,)}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "american-minneapolis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.713302752293578"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_cv.score(list(X_val['w2v']), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "passing-array",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                 ai&tech       0.65      0.77      0.71       194\n",
      "                business       0.63      0.58      0.60       194\n",
      "construction&environment       0.85      0.81      0.83       131\n",
      "     consumer&automotive       0.81      0.79      0.80       190\n",
      "                 finance       0.70      0.74      0.72       187\n",
      "                 general       0.82      0.67      0.74       221\n",
      "      science&healthcare       0.76      0.84      0.80       192\n",
      "\n",
      "                accuracy                           0.74      1309\n",
      "               macro avg       0.75      0.74      0.74      1309\n",
      "            weighted avg       0.74      0.74      0.74      1309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn_pred = nn_cv.predict(list(X_test['w2v']))\n",
    "\n",
    "print(classification_report(y_test, nn_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-summary",
   "metadata": {},
   "source": [
    "### Logistic regression model use 'content' and 'domain' as predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "medium-surveillance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb=LabelBinarizer()\n",
    "lb.fit(data.domain)\n",
    "domain_bi = lb.transform(data.domain)\n",
    "\n",
    "data=data.assign(domain_bi=list(domain_bi))\n",
    "two_df=pd.concat([data['domain_bi'], data['w2v']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "acoustic-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['domain_w2v']=two_df.apply(lambda row: list(row[\"domain_bi\"])+list(row[\"w2v\"]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "postal-veteran",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_vt, y_train, y_vt = train_test_split(data, data.topic_area, test_size = 0.2, random_state = 42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_vt, y_vt, test_size = 0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "printable-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_domain = LogisticRegression(max_iter=1000000, C = 1000, random_state=42).fit(list(X_train['domain_w2v']), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "hazardous-lewis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                 ai&tech       1.00      1.00      1.00       194\n",
      "                business       1.00      1.00      1.00       194\n",
      "construction&environment       1.00      1.00      1.00       131\n",
      "     consumer&automotive       1.00      1.00      1.00       190\n",
      "                 finance       1.00      1.00      1.00       187\n",
      "                 general       1.00      1.00      1.00       221\n",
      "      science&healthcare       1.00      1.00      1.00       192\n",
      "\n",
      "                accuracy                           1.00      1309\n",
      "               macro avg       1.00      1.00      1.00      1309\n",
      "            weighted avg       1.00      1.00      1.00      1309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_pred_domain = lr_domain.predict(list(X_test['domain_w2v']))\n",
    "\n",
    "print(classification_report(y_test, lr_pred_domain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-hazard",
   "metadata": {},
   "source": [
    "## GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "applied-couple",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "glove_file = 'glove.6B/glove.6B.100d.txt'\n",
    "tmp_file = get_tmpfile(\"test_word2vec.txt\")\n",
    "\n",
    "_ = glove2word2vec(glove_file, tmp_file)\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format(tmp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "binary-packing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def doc2vec(doc, wv):\n",
    "    vecs = []\n",
    "    for token in doc.split():\n",
    "        try:\n",
    "            vecs.append(wv[token])\n",
    "        except KeyError:\n",
    "            pass\n",
    "    if len(vecs) == 0:\n",
    "        return np.zeros(100)\n",
    "    else:\n",
    "        return np.array(np.mean(vecs, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "stuck-conversation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13082/13082 [00:22<00:00, 580.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13082 13082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "for doc in tqdm(data.content):\n",
    "    X.append(doc2vec(doc, model))\n",
    "y = list(data['topic_area'])\n",
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "quick-watershed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['glove'] = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "legendary-chick",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_vt, y_train, y_vt = train_test_split(data, data.topic_area, test_size = 0.2, random_state = 42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_vt, y_vt, test_size = 0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-knight",
   "metadata": {},
   "source": [
    "### Logistic Regression using 'content' as sole predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "going-tutorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_glove = LogisticRegression(max_iter=1000000, C = 1, random_state=42).fit(list(X_train['glove']), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "understood-temperature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                 ai&tech       0.50      0.51      0.51       204\n",
      "                business       0.54      0.33      0.41       207\n",
      "construction&environment       0.72      0.60      0.65       105\n",
      "     consumer&automotive       0.60      0.65      0.62       190\n",
      "                 finance       0.59      0.61      0.60       196\n",
      "                 general       0.60      0.74      0.66       198\n",
      "      science&healthcare       0.65      0.71      0.68       208\n",
      "\n",
      "                accuracy                           0.59      1308\n",
      "               macro avg       0.60      0.59      0.59      1308\n",
      "            weighted avg       0.59      0.59      0.58      1308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "lr_pred0_glove = lr_glove.predict(list(X_val['glove']))\n",
    "\n",
    "print(classification_report(y_val, lr_pred0_glove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "general-amount",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = [1000, 100, 10, 1, 0.5, 0.25, 0.1, 0.05, 0.025, 0.01, 0.005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "running-philosophy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=3)]: Done  35 out of  35 | elapsed:   27.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "lr_cv_glove= LogisticRegressionCV(Cs=Cs,\n",
    "                           cv=5,\n",
    "                           solver='liblinear',\n",
    "                           scoring='accuracy',\n",
    "                           random_state=42,\n",
    "                           n_jobs=3,\n",
    "                           verbose=3,\n",
    "                           max_iter=100000000,\n",
    "                           penalty='l2').fit(list(X_train['glove']), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "adverse-relief",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "                 ai&tech       0.61      0.63      0.62       194\n",
      "                business       0.46      0.34      0.39       194\n",
      "construction&environment       0.84      0.69      0.76       131\n",
      "     consumer&automotive       0.70      0.68      0.69       190\n",
      "                 finance       0.52      0.62      0.57       187\n",
      "                 general       0.68      0.75      0.71       221\n",
      "      science&healthcare       0.73      0.82      0.78       192\n",
      "\n",
      "                accuracy                           0.65      1309\n",
      "               macro avg       0.65      0.65      0.65      1309\n",
      "            weighted avg       0.64      0.65      0.64      1309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_pred_glove = lr_cv_glove.predict(list(X_test['glove']))\n",
    "\n",
    "print(classification_report(y_test, lr_pred_glove))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
